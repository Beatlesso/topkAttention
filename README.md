# topkAttention
目前pytorch版本的实现在MyAttention.py中，总共三个版本，目前测试三个结果是一致的
第一个版本和暴力无差别，最能保证正确性，需要额外topk倍的显存，速度很慢
第二个版本避免了显示存储k和v，避免了额外的显存，但是速度比第一个版本还要慢
第三个版本速度最快，但是仍然无法避免topk倍的额外显存占用

测试使用的代码在test.py中